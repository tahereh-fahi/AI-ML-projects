{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahereh-fahi/AI-ML-projects/blob/main/networks_socialnetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc0NPzswjRyA"
      },
      "source": [
        "# Part 1: from data to networks, using Python networkx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FASlp0IWjRyB"
      },
      "source": [
        "# I - Why studying social networks? Which areas/which questions to study?\n",
        "\n",
        "- **To get a better understanding of people's behavior**\n",
        "  - Our social networks influence our economic decisions, from what bank we use or stocks we invest in (e.g., Robinhood)\n",
        "    to which brands we buy (e.g., based on our friends' posts on Instagram, or Pages' recommendations on Facebook).\n",
        "  - Networks may also trigger adverse reactions that need to be prevented, and therefore need to be monitored (e.g., the\n",
        "    propagation of misinformation on social media and via online news)\n",
        "  - Recommended reading: [Using gossips to spread information](http://stanford.edu/~arungc/BCDJ_gossip.pdf)\n",
        "    \n",
        "    \n",
        "- **To build new models and theories of social networks**\n",
        "  - Networks evolve over time, and your connections are most likely to change as you move to another university or switch jobs.\n",
        "    There is ongoing research on the theory of dynamic social networks: how do they get formed? what makes them grow? can we\n",
        "    predict the size and shape of a network one or two years from now?\n",
        "  - This is an active area of research in complex systems and computer science, but also one where progress is made via empirical\n",
        "    work in the field (e.g., experiments in the developing world in collaboration with local partners) or large-scale online\n",
        "    experiments such as the one Facebook and Microsoft have developed the infrastructure for.    \n",
        "    Recommended reading: [Studying social networks in the developing world](https://www.gsb.stanford.edu/insights/studying-social-networks-developing-worlds-five-key-insights)   \n",
        "    \n",
        "- **To optimize for information diffusion or resource allocation**\n",
        "  - Imagine we want to inform teenagers about HIV via prevention programs in homeless communities. It would be helpful to know or\n",
        "    quickly learn about underlying friendship networks to best propagate the information.\n",
        "  - Imagine we want to optimally distribute tests across cities in a province during an epidemic outbreak, under resource\n",
        "    constraints (e.g., we have a limited number of kits to distribute) and as the infection is spreading. We would greatly\n",
        "    benefit from the knowledge of commuting flows and traffic between each locality!\n",
        "  - Recommended reading: [Influence maximization with an uncertain network](https://dl.acm.org/doi/10.5555/3091125.3091306)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjMJFAEHZ_H8"
      },
      "source": [
        "# Network Analysis Project — MITx 6.419x\n",
        "\n",
        "This notebook is part of the course **Data Analysis: Statistical Modeling and Computation in Applications (MITx 6.419x)**.  \n",
        "It explores **social network datasets** (Facebook and Twitter, from the Stanford SNAP repository) to study the structure and properties of large-scale graphs.\n",
        "\n",
        "### Objectives\n",
        "- Construct and visualize real-world networks from edge-list data.\n",
        "- Explore **degree distributions** and test for **power-law behavior**.\n",
        "- Compute and interpret a range of **centrality measures**:\n",
        "  - Degree, closeness, betweenness, eigenvector, harmonic, PageRank, HITS.\n",
        "- Evaluate global graph statistics such as **diameter** and **density**.\n",
        "- Apply **community detection** (Louvain, greedy modularity) to uncover network structure.\n",
        "- Visualize subgraphs with nodes scaled/colored by metrics or community.\n",
        "\n",
        "### Why this matters\n",
        "Understanding network structure helps explain **influence, diffusion, and community formation** in real social systems.  \n",
        "This project combines **statistical modeling** and **computational tools (Python + NetworkX)** to highlight how theory and computation come together in applied network science.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSWWymckaBDe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-7IidGXjRyB"
      },
      "source": [
        "# II - How do we go from data to networks?\n",
        "\n",
        "Mathematically, $G = (\\mathcal{N}, \\mathcal{E})$.\n",
        "\n",
        "$\\mathcal{N}$ denotes the set of nodes. Some may be isolated (i.e., they are not connected to any other node).\n",
        "\n",
        "$\\mathcal{E}$ denotes the set of edges (i.e., typically the most-left node is the individual the link is emerging \"from\", and the most-right node is the individual \"to\" whom the connection goes).\n",
        "\n",
        "There are mainly two ways to store network-related information.\n",
        "\n",
        "**Option 1:**\n",
        "We often store networks as *tabular data*, e.g.\n",
        "- `nodes.csv` contains node ids and node attributes.\n",
        "- `edges.csv` contains ids of source and target node, plus edge attributes.\n",
        "\n",
        "**Option 2:**\n",
        "We store an *edge list* (which is the repository of all existing connections), e.g., as a simple text file `edge_list.txt`.\n",
        "\n",
        "**What is the main difference between these two options?**\n",
        "- `nodes.csv` will usually contain information about all nodes, even those that are isolated, i.e., those that are not connected to any other nodes in the network.\n",
        "- `edge_list.txt` is biased towards nodes that have at least one connection (so there is potentially one isolated part of the network that is not captured here).\n",
        "\n",
        "**Our recitation today:**\n",
        "Today, we will practice going from an *edge list* to a network object that we can actually study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk27pvl2jRyB"
      },
      "source": [
        "# III - Data we will be using in this session\n",
        "\n",
        "- Ego networks (\"friends lists\") from Facebook, for only 10 members.\n",
        "- We are working with only a subset of this large time-varying network.\n",
        "- The full dataset, captured at a certain point in time, is accessible [on Stanford Network Analysis Project website](https://snap.stanford.edu/data/egonets-Facebook.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYThEIUKjRyB"
      },
      "source": [
        "## 1) What type of data are we studying?\n",
        "\n",
        "The networks discussed in this recitation are **“egocentric” networks**.\n",
        "\n",
        "- The term **“ego”** is used to denote a person connected to everyone in the network.\n",
        "- An ego network is the social world from **ego**'s point of view.\n",
        "- It is convention to use the term **“alter”** to refer to anyone else in the network.\n",
        "- This way, one can talk about both friends and followers or fans; it does not matter what role they play: from **ego's perspective**, they are all alters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6cb4IIGjRyB"
      },
      "source": [
        "![network_recitation_ego.jpg](attachment:network_recitation_ego.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "437-d7ZqjRyB"
      },
      "source": [
        "- On the left: **1.0 network** (basic knowledge: ego + their friends)\n",
        "- In the middle: **1.5 network** (available knowledge: via Facebook API)\n",
        "- On the right: **2.0 network** (ideal, but not readily available: would be possible via web-scraping for instance, but not made\n",
        "  accessible via the API for the protection of the user's privacy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtBxEPr2jRyB"
      },
      "source": [
        "## 2) Data characteristics - Let us get familar with the original source!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6tbCLpkjRyC"
      },
      "source": [
        "The data used in this recitation is from https://snap.stanford.edu/data/ego-Facebook.html. The data file     facebook_combined.txt is already included in the zip folder which contains this notebook.\n",
        "\n",
        "You can download [facebook_combined.txt.gz](https://snap.stanford.edu/data/facebook_combined.txt.gz) --Edges from all egonets combined, from the bottom of the page, and decompress into .txt file.\n",
        "\n",
        "\n",
        "![networks_data_source.png](attachment:networks_data_source.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF4zG-ozjRyC"
      },
      "source": [
        "**Attribution:** The material below borrows from [this excellent blog post](https://blog.dominodatalab.com/social-network-analysis-with-networkx/), that we would recommend you to explore further after this session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0FhmgbNjRyC"
      },
      "source": [
        "# IV - Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIe247jSjRyC"
      },
      "source": [
        "## 1) Required Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hifbT_hY-fKw"
      },
      "outputs": [],
      "source": [
        "# --- Setup: always get a clean, working NetworkX + Louvain ---\n",
        "import sys, shutil, glob, pathlib\n",
        "\n",
        "# Remove any stale/mismatched networkx installs\n",
        "import importlib.util\n",
        "spec = importlib.util.find_spec(\"networkx\")\n",
        "if spec and spec.origin:\n",
        "    pkg_dir = pathlib.Path(spec.origin).parent\n",
        "    shutil.rmtree(pkg_dir, ignore_errors=True)\n",
        "    for pattern in (\"networkx-*.dist-info\", \"networkx-*.egg-info\"):\n",
        "        for d in glob.glob(str(pkg_dir.parent / pattern)):\n",
        "            shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Reinstall exact versions known to work with Python 3.12+\n",
        "!{sys.executable} -m pip install --no-cache-dir --force-reinstall \"networkx==3.2.1\" \"python-louvain==0.16\"\n",
        "\n",
        "# --- End setup ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzva4BpeHctM"
      },
      "outputs": [],
      "source": [
        "!pip install -U \"pip>=24\" \"setuptools>=70\" \"wheel>=0.43\"\n",
        "!pip install -U \"numpy>=2.0,<3\" \"scikit-learn>=1.4,<2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhucDEyp-oWh"
      },
      "outputs": [],
      "source": [
        "import networkx as nx, community as community_louvain\n",
        "print(nx.__version__)   # should be 3.2.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnFY_IaujRyC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd    # for reading and manipulating tabular data\n",
        "import networkx as nx  # for constructing and studying networks\n",
        "import numpy as np     # for arrays\n",
        "#import community           # for community structure later\n",
        "import collections          # for manipulation tuples and zipping objects\n",
        "import statistics as stats  # for generating summary statistics\n",
        "import time                 # for measuring computating time\n",
        "from matplotlib import pyplot as plt  # for outputting nice plots\n",
        "import seaborn as sns                 # for creating even nicer plots\n",
        "\n",
        "get_ipython().magic(u'matplotlib inline')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aoq__XsjRyD"
      },
      "source": [
        "## 2) Read and inspect the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLgEiCjuBzf0"
      },
      "outputs": [],
      "source": [
        "# --- RUN ME: download & prepare multiple datasets from GitHub Releases ------\n",
        "import os, subprocess, hashlib, pathlib, zipfile, tarfile\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "def download(url: str, out_path: str):\n",
        "    print(f\"\\nDownloading {url} -> {out_path}\")\n",
        "    subprocess.run(\n",
        "        [\"curl\", \"-L\", \"--fail\", \"--retry\", \"3\", \"--retry-delay\", \"3\", \"-o\", out_path, url],\n",
        "        check=True\n",
        "    )\n",
        "\n",
        "def sha256sum(path: str) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1<<20), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def verify(path: str, expected_sha256: str | None):\n",
        "    if not expected_sha256:\n",
        "        print(\"Skipping checksum verification.\")\n",
        "        return\n",
        "    actual = sha256sum(path)\n",
        "    if actual.lower() != expected_sha256.lower():\n",
        "        raise RuntimeError(\n",
        "            f\"Checksum mismatch for {path}\\nexpected: {expected_sha256}\\nactual:   {actual}\"\n",
        "        )\n",
        "    print(\"Checksum OK:\", actual)\n",
        "\n",
        "def extract_if_archive(path: str, dest_dir=\"data\"):\n",
        "    p = pathlib.Path(path)\n",
        "    name = p.name.lower()\n",
        "    if name.endswith(\".zip\"):\n",
        "        with zipfile.ZipFile(path) as z:\n",
        "            z.extractall(dest_dir)\n",
        "        print(\"Unzipped to\", dest_dir)\n",
        "    elif name.endswith(\".tar.gz\") or name.endswith(\".tgz\"):\n",
        "        with tarfile.open(path, \"r:gz\") as t:\n",
        "            t.extractall(dest_dir)\n",
        "        print(\"Extracted tar.gz to\", dest_dir)\n",
        "    elif name.endswith(\".gz\"):\n",
        "        # leave .gz as-is (often a single text file); user may read via gzip in code\n",
        "        print(\"Gzip file detected; leaving compressed. (Use gzip.open to read.)\")\n",
        "    else:\n",
        "        print(\"Not an archive; nothing to extract.\")\n",
        "\n",
        "# === List all datasets you want to fetch ====================================\n",
        "DATASETS = [\n",
        "    {\n",
        "        \"label\": \"facebook\",\n",
        "        \"url\": \"https://github.com/tahereh-fahi/Data/releases/download/v1.0.3/facebook_combined.txt.zip\",\n",
        "        \"out\": \"data/facebook_combined.txt.zip\",\n",
        "        \"sha256\": \"d2b1cb6e56ba91031c78780b95e612686ddd6de6bea6697ad48533bab0b9177b\",\n",
        "        \"extract_to\": \"data\"\n",
        "    },\n",
        "    {\n",
        "        \"label\": \"twitter\",\n",
        "        \"url\": \"https://github.com/tahereh-fahi/Data/releases/download/v1.0.3/twitter_combined.txt.gz\",\n",
        "        \"out\": \"data/twitter_combined.txt.gz\",\n",
        "        # paste the exact SHA-256 GitHub shows for this asset, or set to None to skip:\n",
        "        \"sha256\": None,\n",
        "        \"extract_to\": \"data\"\n",
        "    },\n",
        "]\n",
        "# ============================================================================\n",
        "\n",
        "for item in DATASETS:\n",
        "    print(f\"\\n=== [{item['label']}] ===\")\n",
        "    download(item[\"url\"], item[\"out\"])\n",
        "    verify(item[\"out\"], item.get(\"sha256\"))\n",
        "    extract_if_archive(item[\"out\"], item.get(\"extract_to\", \"data\"))\n",
        "\n",
        "print(\"\\nReady. Your files are in ./data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUY--J6OjRyD"
      },
      "source": [
        "Sometimes we need to do more complex network construction. In this case our data is very simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6Z8JF02jRyD"
      },
      "outputs": [],
      "source": [
        "facebook_data_file = '/content/data/facebook_combined.txt'\n",
        "\n",
        "# Create graph from edge list stored in data file\n",
        "G = nx.read_edgelist(facebook_data_file,\n",
        "                     create_using = nx.Graph(), # Use Graph() instead of DiGraph() for directed vs. undirected,\n",
        "                     nodetype = int) # Do not forget to specify node information type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ROQhpIEjRyD"
      },
      "source": [
        "## Let's inspect..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlniRJWUjRyD"
      },
      "source": [
        "It's often useful to get these numbers programmatically; let's practice:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kwck7DUsjRyD"
      },
      "outputs": [],
      "source": [
        "G_nodes = G.nodes()\n",
        "G_edges = G.edges()\n",
        "\n",
        "print(type(G_nodes))\n",
        "print(type(G_edges))\n",
        "\n",
        "print(str(len(G_nodes)) + ' nodes, ' + str(len(G_edges)) + ' edges')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R88FEdDujRyD"
      },
      "source": [
        "Let us create a function that return this information for any graph, as we will often need it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ScVgdxujRyD"
      },
      "outputs": [],
      "source": [
        "def graph_stats(graph):\n",
        "    stats = 'Here is the composition of the graph: ' + str(len(graph.nodes())) + ' nodes, ' + str(len(graph.edges())) + ' edges'\n",
        "    return(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRr6_AfGjRyD"
      },
      "outputs": [],
      "source": [
        "# Example with graph G that we have just created\n",
        "graph_stats(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWB_sg6njRyD"
      },
      "source": [
        "## 3) Accessing edge and node data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJB9LWc0jRyD"
      },
      "outputs": [],
      "source": [
        "# We need to transform the node view into a list to manipulate the object.\n",
        "G_nodes_list = list(G.nodes())\n",
        "G_nodes_list[20:30] # for nxv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBQe59GkjRyD"
      },
      "outputs": [],
      "source": [
        "# Show that the length of the node list matches the original length.\n",
        "print('Length of transformed list: ', len(G_nodes_list))\n",
        "print('Length of original list: ', len(G.nodes()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sot7FRcfjRyD"
      },
      "outputs": [],
      "source": [
        "# We need to transform the edge view into a list to manipulate the object.\n",
        "G_edges_list = list(G.edges())\n",
        "G_edges_list[1000:1030] # for nxv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzWUoGjejRyD"
      },
      "outputs": [],
      "source": [
        "# Show that the length of the edge list matches the original length.\n",
        "print('Length of transformed list: ', len(G_edges_list))\n",
        "print('Length of original list: ', len(G.edges()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEbBLyAjjRyD"
      },
      "outputs": [],
      "source": [
        "# Randomly pick a few edges in the object casted to a list to sanity check.\n",
        "from random import randint\n",
        "\n",
        "num_edges = 3\n",
        "edge_indices = [randint(0, len(G_edges_list)) for i in range(num_edges)]\n",
        "\n",
        "print('Indices: ', edge_indices)\n",
        "random_edges = [G_edges_list[e] for e in edge_indices]\n",
        "print('List of edges corresponding to these indices: ', random_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgc10REzjRyD"
      },
      "source": [
        "# V - Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3__xUgJjRyD"
      },
      "outputs": [],
      "source": [
        "# Network metric statistics\n",
        "def network_metric_statistics(metric_data):\n",
        "    avg = stats.mean(metric_data)\n",
        "    med = stats.median(metric_data)\n",
        "    std = stats.stdev(metric_data)\n",
        "\n",
        "    return(\"Here is a quick summary of your data: average = \" + '{:.5f}'.format(avg) + \", median = \" + '{:.5f}'.format(med) + \", standard deviation = \" + '{:.5f}'.format(std))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjkSq7izjRyD"
      },
      "outputs": [],
      "source": [
        "# That is a generic function (you can apply it to any list---a metric of interest to you), and we will be looking at examples later on.\n",
        "# We will first take a look at the degree distribution scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs4Qt6c7jRyD"
      },
      "outputs": [],
      "source": [
        "# social ties\n",
        "# levels of friendship / quantify friendship / identify Faceobook members"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPos46_RjRyD"
      },
      "source": [
        "## 1) Empirical Degree Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7jSbKMqjRyE"
      },
      "outputs": [],
      "source": [
        "print(type(G.degree))\n",
        "print(G.degree[0])\n",
        "# more complicated when each node is not an integer\n",
        "# sanity check the degree of node 0 (easy to read from the edge list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d73wEgsgjRyE"
      },
      "outputs": [],
      "source": [
        "# Transform degree view into a list.\n",
        "degree_sequence = sorted((G.degree[d] for d in range(len(G.degree))), reverse=True)  # for nx v2\n",
        "print(type(degree_sequence))\n",
        "print(degree_sequence[:5]) # from largest to smallest degree value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRllTcxSjRyE"
      },
      "outputs": [],
      "source": [
        "network_metric_statistics(degree_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkPTXlh6jRyM"
      },
      "outputs": [],
      "source": [
        "# degree distribution - meaning the number of edges of each node, using the network terminology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZF4_zJqjRyM"
      },
      "outputs": [],
      "source": [
        "degree_count = collections.Counter(degree_sequence)\n",
        "deg, cnt = zip(*degree_count.items())\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.bar(deg, cnt, width=1, color='b')\n",
        "plt.xlabel(\"Node degree size\", fontsize=20)\n",
        "plt.ylabel(\"Frequency\", fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.title(\"Entire graph - Node degree distribution\", fontsize=20)\n",
        "plt.show()\n",
        "\n",
        "# zoom on x-axis being around 900-1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A8QVnltjRyM"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.set(font_scale=2)\n",
        "ax = sns.histplot(degree_sequence, kde=True) # Use histplot instead of distplot\n",
        "ax.set(xlabel=\"Node degree size\",ylabel= \"Frequency\",title='Entire graph - Node degree distribution');\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AIbD1K3jRyM"
      },
      "source": [
        "## b) Review of power law distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eZJgYQ4jRyM"
      },
      "source": [
        "**i) How do you recognize a power law distribution? What are some of its key characteristics?**\n",
        "\n",
        "- Distribution is right skewed (as compared to normal distribution, e.g., height in the human populations)\n",
        "- High ratio of max to min (as compared to normal distribution, e.g., tallest person vs. smallest person in the world)\n",
        "- No matter what scale you look at it, it looks the same (i.e., the shape of the distribution is the same, to a multiplying       factor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DollNcuzjRyM"
      },
      "source": [
        "**ii) Discrete probability power law distribution, indexed by the degree value k (k greater than $k_{min})$**\n",
        "\n",
        "$p(k) = \\frac{\\alpha-1}{k_{min}}.(\\frac{k}{k_{min}})^{-\\alpha}$\n",
        "\n",
        "- $\\alpha$ is the power in the **power law**\n",
        "- $k_{min}$ is the minimum degree for which the **discrete probability law** applies\n",
        "\n",
        "Let us take the logarithm on each side. What does that lead to?\n",
        "\n",
        "For degree k greater than $k_{min}$:\n",
        "$log(p(k)) = log(\\frac{\\alpha-1}{k_{min}}) - \\alpha.log(\\frac{k}{k_{min}})$\n",
        "\n",
        "The above expression is linear in $log(\\frac{k}{k_{min}})$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so1Y58LujRyM"
      },
      "source": [
        "**iii) Analogy with linear function: y = cx + b**\n",
        "\n",
        "- $y = log(p(k))$\n",
        "- $x = log(\\frac{k}{k_{min}})$\n",
        "- Intercept: $b = log(\\frac{\\alpha-1}{k_{min}})$\n",
        "- Slope: $c = -\\alpha$\n",
        "\n",
        "*Note: while the distribution of the degree is a discrete distribution (recall: the degree of a node is integer-valued), we will be approximating it by a continuous distribution - to facilitate the calibration of the parameter $\\alpha$.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqe3UAwbjRyM"
      },
      "source": [
        "\n",
        "\n",
        "![powerlaw.png](attachment:powerlaw.png)\n",
        "Attribution: Image modified from the paper [Power laws, Pareto distributions and Zipf’s law](https://arxiv.org/pdf/cond-mat/0412004.pdf), by M. E. J. Newman:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRR4h5ZajRyM"
      },
      "source": [
        "**iv) Why a power law? Why not an exponential distribution?**\n",
        "- Many social networks are power laws. See this famous [Science paper](https://arxiv.org/pdf/cond-mat/9910332.pdf%3Forigin%3Dpublication_detail) from Reka Albert and Albert-Laszlo Barabasi.\n",
        "- For a social network, there would not be any interpretation of the half-time, which is often used in physics and in operations   management.\n",
        "- For an exponential distribution, a stricter assumption is made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izWv75qdjRyM"
      },
      "source": [
        "**v) How prominent is this in nature?**\n",
        "- What characteristics of social networks are also present in other networks, which make them exhibit a power law distribution?\n",
        "- How to decide that I should fit a power law? What are the characteristics, similar to a social network, that would help me determine that this is the right underlying model?\n",
        "- Other examples: energy networks, transportation networks etc. (e.g., tree structure, importance of hierarchy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1vJ_NzwjRyM"
      },
      "source": [
        "For example, below are cumulative distributions or “rank/frequency plots” of twelve quantities reputed to follow power laws, taken from the paper [Power laws, Pareto distributions and Zipf’s law](https://arxiv.org/pdf/cond-mat/0412004.pdf), by M. E. J. Newman:\n",
        "\n",
        "![powerlaweverywhere.png](attachment:powerlaweverywhere.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70djHBZajRyM"
      },
      "source": [
        "![evenmorepowerlaw.png](attachment:evenmorepowerlaw.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW5eQHlljRyN"
      },
      "source": [
        "## 3) Application: fitting a power law distribution (simple version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFn76OayjRyN"
      },
      "source": [
        "### a) Standard analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GIy9hxqjRyN"
      },
      "outputs": [],
      "source": [
        "# Try both\n",
        "# Overlay the two distributions - with different parameters in the notebook (for loop on lambda decay values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIBMfWNFjRyN"
      },
      "outputs": [],
      "source": [
        "# it should look linear on a log-log scale\n",
        "\n",
        "log_deg = np.log(deg)\n",
        "log_cnt = np.log(cnt)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.plot(log_deg, log_cnt, color='b')\n",
        "plt.xlabel('Logarithm of node degree size', fontsize=20)\n",
        "plt.ylabel('Logarithm of frequency', fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.title(\"Entire graph - Node degree distribution - Log-log scale\", fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ4e6WjVjRyN"
      },
      "outputs": [],
      "source": [
        "print(type(cnt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sogf1R9KjRyN"
      },
      "outputs": [],
      "source": [
        "cnt_list = list(cnt)\n",
        "\n",
        "# Scaling factor\n",
        "division_factor = sum(cnt_list[:-1]) # remove degree = 1\n",
        "cnt_proba_list = [cnt_list[i]/division_factor for i in range(len(cnt_list)-1)] # remove degree = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKUrfC61jRyN"
      },
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "print(len(cnt_list))\n",
        "print(len(cnt_proba_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27--7vF2jRyN"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "lm = linear_model.LinearRegression()\n",
        "\n",
        "deg_list = list(deg)[:-1]\n",
        "kmin = 2\n",
        "log_deg_list = [np.log(deg_list[i]/kmin) for i in range(len(deg_list))]\n",
        "log_cnt_proba_list = [np.log(e) for e in cnt_proba_list]\n",
        "# Set up the matrix x (no need to create a column of 1's - the intercept is automatically considered when fitting the regression)\n",
        "X = pd.DataFrame({'log_deg': log_deg_list}, columns=['log_deg'])\n",
        "\n",
        "# Linear regression model\n",
        "model = lm.fit(X, log_cnt_proba_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQyhKZVOjRyN"
      },
      "outputs": [],
      "source": [
        "# Check the slope c\n",
        "c = model.coef_[0]\n",
        "print('Slope c: ', c)\n",
        "# Deduce the value of alpha\n",
        "alpha = -c\n",
        "print('Exponent alpha: ', alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwMRNP-PjRyN"
      },
      "outputs": [],
      "source": [
        "# Check the intercept b\n",
        "b = model.intercept_\n",
        "print('Intercept b: ', b)\n",
        "# Check whether it deviates from its theoretical value: log(alpha-1/kmin)\n",
        "theoretical_b = np.log((alpha-1)/kmin)\n",
        "print('Theoretical b, using the estimated value for alpha: ', theoretical_b)\n",
        "print('% absolute error: ', np.round((-b+theoretical_b)/theoretical_b*100,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bivC820jRyN"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import curve_fit\n",
        "\n",
        "def exponential_func(x, a):\n",
        "    return a*np.exp(-a*x)\n",
        "\n",
        "popt, pcov = curve_fit(exponential_func, deg_list, cnt_proba_list, p0=(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdl39nZojRyN"
      },
      "outputs": [],
      "source": [
        "popt[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UijrkroVjRyN"
      },
      "outputs": [],
      "source": [
        "# Mean absolute error - Overall\n",
        "print(deg_list)\n",
        "predictions_expo = [popt[0] * np.exp(-popt[0]*e) for e in deg_list]\n",
        "predictions_expo = np.array(predictions_expo)\n",
        "print(sum(predictions_expo))\n",
        "print(predictions_expo[190:])\n",
        "print((abs(predictions_expo/sum(predictions_expo) - cnt_proba_list)).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTlVzT0LjRyN"
      },
      "source": [
        "### b) Goodness of fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hSx8AwsjRyN"
      },
      "outputs": [],
      "source": [
        "predictions = lm.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYC9r8OEjRyN"
      },
      "outputs": [],
      "source": [
        "print(np.exp(predictions[:10]))# show the non log version\n",
        "print(cnt_proba_list[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biuJ0s_zjRyN"
      },
      "outputs": [],
      "source": [
        "sum(np.exp(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5xyJuqMjRyN"
      },
      "outputs": [],
      "source": [
        "# Magnitude of the prediction error for small values of k\n",
        "print(np.exp(predictions)[200:210])\n",
        "print(cnt_proba_list[200:210])\n",
        "print((abs(np.exp(predictions)[200:210] - cnt_proba_list[200:210])).mean())\n",
        "\n",
        "# Magnitude of the prediction error for large values of k\n",
        "print(np.exp(predictions)[:10])\n",
        "print(cnt_proba_list[:10])\n",
        "print((abs(np.exp(predictions)[:10] - cnt_proba_list[:10])).mean())\n",
        "\n",
        "# Mean absolute error - Overall\n",
        "sum_predictions = sum(np.exp(predictions))\n",
        "print(sum_predictions)\n",
        "print((abs(np.exp(predictions)/sum_predictions - cnt_proba_list)).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yipndw2-jRyN"
      },
      "outputs": [],
      "source": [
        "predictions_reverse = np.exp(predictions)[::-1]/sum_predictions\n",
        "predictions_cumsum = pd.Series(predictions_reverse)\n",
        "cumsum = predictions_cumsum.cumsum()\n",
        "#print(cumsum)\n",
        "print(len(cumsum))\n",
        "\n",
        "predictions_expo_reverse = predictions_expo[::-1]/sum(predictions_expo)\n",
        "predictions_expo_cumsum = pd.Series(predictions_expo_reverse)\n",
        "expo_cumsum = predictions_expo_cumsum.cumsum()\n",
        "\n",
        "cnt_proba_list_reverse = cnt_proba_list[::-1]\n",
        "cnt_proba_list_cumsum = pd.Series(cnt_proba_list_reverse)\n",
        "cnt_cumsum = cnt_proba_list_cumsum.cumsum()\n",
        "#print(cnt_cumsum)\n",
        "print(len(cnt_cumsum))\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.plot(cnt_cumsum, color='b', label='Modelled - Power law')\n",
        "plt.plot(cumsum, color='r', label='Empirical')\n",
        "plt.plot(expo_cumsum, color='g', label='Modelled - Expo')\n",
        "plt.xlabel('Node degree size k', fontsize=20)\n",
        "plt.ylabel('Cumulative probability: P(node degree <= k)', fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.title(\"Cumulative probability distribution\", fontsize=20)\n",
        "leg=plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC7Nj6LZjRyN"
      },
      "source": [
        "### c) Modeling without outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtG5Rf06jRyN"
      },
      "outputs": [],
      "source": [
        "# let us do analysis without the outliers, i.e., for degree k <= 200 (right truncation)\n",
        "degree_upper_bound = 200\n",
        "restricted_degree_sequence = [degree_sequence[i] for i in range(len(degree_sequence)) if degree_sequence[i] <= degree_upper_bound]\n",
        "\n",
        "restricted_degree_count = collections.Counter(restricted_degree_sequence)\n",
        "restricted_deg, restricted_cnt = zip(*restricted_degree_count.items())\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.bar(restricted_deg, restricted_cnt, width=1, color='b')\n",
        "plt.xlabel(\"Node degree size\", fontsize=20)\n",
        "plt.ylabel(\"Frequency\", fontsize=20)\n",
        "plt.title(\"Zoom - Node degree distribution\", fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xeydli1jRyO"
      },
      "outputs": [],
      "source": [
        "restricted_log_deg = np.log(restricted_deg)\n",
        "restricted_log_cnt = np.log(restricted_cnt)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.plot(restricted_log_deg, restricted_log_cnt, color='b')\n",
        "plt.xlabel('Logarithm of node degree size', fontsize=20)\n",
        "plt.ylabel('Logarithm of frequency', fontsize=20)\n",
        "plt.title(\"Zoom - Node degree distribution - Log-log scale\", fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ1OMmQjjRyO"
      },
      "outputs": [],
      "source": [
        "restricted_cnt_list = list(restricted_cnt)\n",
        "\n",
        "# Scaling factor\n",
        "restricted_division_factor = sum(restricted_cnt_list) # remove degree = 1\n",
        "restricted_cnt_proba_list = [restricted_cnt_list[i]/restricted_division_factor for i in range(len(restricted_cnt_list))] # remove degree = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-8jTzyrjRyO"
      },
      "outputs": [],
      "source": [
        "restricted_lm = linear_model.LinearRegression()\n",
        "\n",
        "restricted_deg_list = list(restricted_deg)\n",
        "kmin = 2\n",
        "log_restricted_deg_list = [np.log(restricted_deg_list[i]/kmin) for i in range(len(restricted_deg_list))]\n",
        "log_restricted_cnt_proba_list = [np.log(e) for e in restricted_cnt_proba_list]\n",
        "# Set up the matrix x (no need to create a column of 1's - the intercept is automatically considered when fitting the regression)\n",
        "restricted_X = pd.DataFrame({'log_restricted_deg': log_restricted_deg_list}, columns=['log_restricted_deg'])\n",
        "\n",
        "# Linear regression model\n",
        "restricted_model = restricted_lm.fit(restricted_X, log_restricted_cnt_proba_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPDw_F2CjRyO"
      },
      "outputs": [],
      "source": [
        "print(restricted_lm.score(restricted_X, log_restricted_cnt_proba_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVXkLlnfjRyO"
      },
      "outputs": [],
      "source": [
        "# Check the slope\n",
        "print('Slope, using restricted degree range: ', restricted_model.coef_[0])\n",
        "print('Slope, using unrestricted degree range: ', model.coef_[0])\n",
        "\n",
        "print('Absolute percentage difference in slope: ', round(-abs(restricted_model.coef_[0]-model.coef_[0])/model.coef_[0]*100,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZx-VsS0jRyO"
      },
      "outputs": [],
      "source": [
        "# Check the intercept\n",
        "print('Intercept, using restricted degree range: ', restricted_model.intercept_)\n",
        "print('Intercept, using unrestricted degree range: ', model.intercept_)\n",
        "\n",
        "print('Absolute percentage difference in intercept: ', round(-abs(restricted_model.intercept_-model.intercept_)/model.intercept_*100,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABQgYxH1jRyO"
      },
      "outputs": [],
      "source": [
        "# one model with kmax\n",
        "# which model do I prefer? one is giving better fit, but more complicated\n",
        "# is that changing the key parameter (alpha)?\n",
        "# what is the difference between the two estimates?\n",
        "# what will prompt me to choose one model or another? (kmax - would introduce another parameter, I would need another model to represent\n",
        "# the world between kmax and infinity: between 200 and 1045 I don't many points )\n",
        "# if there was a huge difference, I would have opted for kmax and kmin, but not tried to model kmax infinity because not enough data\n",
        "# trained -\n",
        "# chosen the model R2 on valid\n",
        "# test set of egonetworks\n",
        "# do you have more data? otherwise, go with the simplest model / more parsimonious - so more robust to outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjSh4f6cjRyO"
      },
      "outputs": [],
      "source": [
        "restricted_predictions = restricted_lm.predict(restricted_X)\n",
        "\n",
        "print(np.exp(restricted_predictions[:10]))# show the non log version\n",
        "print(restricted_cnt_proba_list[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmA94pz_jRyO"
      },
      "outputs": [],
      "source": [
        "# Magnitude of the prediction error for small values of k\n",
        "print(np.exp(restricted_predictions)[190:])\n",
        "print(restricted_cnt_proba_list[190:])\n",
        "print((abs(np.exp(restricted_predictions)[190:] - restricted_cnt_proba_list[190:])).mean())\n",
        "\n",
        "# Magnitude of the prediction error for large values of k\n",
        "print(np.exp(restricted_predictions)[:10])\n",
        "print(restricted_cnt_proba_list[:10])\n",
        "print((abs(np.exp(restricted_predictions)[:10] - restricted_cnt_proba_list[:10])).mean())\n",
        "\n",
        "# Mean absolute error - Overall\n",
        "print((abs(np.exp(restricted_predictions) - restricted_cnt_proba_list)).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo04e2XrjRyO"
      },
      "outputs": [],
      "source": [
        "# truncated the graph - 2 regimes\n",
        "# power alpha candidate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3_vnPnKjRyO"
      },
      "outputs": [],
      "source": [
        "# Twitter data\n",
        "# followers, retweets\n",
        "# Look at what makes the most sense/is the most tangible\n",
        "\n",
        "# citation network exercise in the homework - (hubs, authorities)\n",
        "# degree is maybe not only the indicator\n",
        "\n",
        "# first order neighborhood level/ transportation (how much of a hub an airport - connections)\n",
        "# but maybe in biological networks you are interested in higher order neighborhood (because indirect connections play a role)\n",
        "# but for some applications the second order info does not even matter\n",
        "\n",
        "# motivation: importance of a node, rely on degree --\n",
        "# How do I know that ppl pointing to me are important?\n",
        "# directionality - learn more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bQzDIyLjRyO"
      },
      "source": [
        "# VI - Directed networks/graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1w5FP9QjRyO"
      },
      "outputs": [],
      "source": [
        "# In order to look at in- and out-degree separately, we first need to construct a directed graph.\n",
        "twitter_data_file = '/content/data/twitter_combined.txt.gz'\n",
        "\n",
        "directed_G = nx.read_edgelist(twitter_data_file,\n",
        "                     create_using = nx.DiGraph(),\n",
        "                     nodetype = int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE_T7Ji7jRyO"
      },
      "outputs": [],
      "source": [
        "directed_G_nodes = list(directed_G.nodes)\n",
        "directed_G_in_degree = list(dict(directed_G.in_degree(directed_G_nodes)).values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEKNh3zRjRyO"
      },
      "outputs": [],
      "source": [
        "in_degree_sequence = sorted((directed_G_in_degree[d] for d in range(len(directed_G.in_degree))), reverse=True)  # degree sequence for nx v2\n",
        "network_metric_statistics(in_degree_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsIuTnpTLf4n"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "# Count in-degrees\n",
        "in_degree_count = collections.Counter(in_degree_sequence)\n",
        "deg, cnt = zip(*sorted(in_degree_count.items()))\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# scatter instead of wide bars\n",
        "plt.scatter(deg, cnt, color='red', s=20, alpha=0.6, edgecolors='k')\n",
        "\n",
        "# log scale (classic for heavy-tailed distributions)\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.xlabel(\"Node in-degree\", fontsize=16)\n",
        "plt.ylabel(\"Frequency\", fontsize=16)\n",
        "plt.title(\"Entire graph — Node in-degree distribution\", fontsize=18)\n",
        "plt.grid(True, which=\"both\", ls=\"--\", lw=0.5, alpha=0.7)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFlWtwLRjRyO"
      },
      "outputs": [],
      "source": [
        "directed_G_out_degree = list(dict(directed_G.out_degree(directed_G_nodes)).values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM46vWfFjRyO"
      },
      "outputs": [],
      "source": [
        "out_degree_sequence = sorted((directed_G_out_degree[d] for d in range(len(directed_G.out_degree))), reverse=True)  # degree sequence for nx v2\n",
        "network_metric_statistics(out_degree_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhCp7qZzLuHS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "\n",
        "# Count out-degrees\n",
        "out_degree_count = collections.Counter(out_degree_sequence)\n",
        "out_deg, out_cnt = zip(*sorted(out_degree_count.items()))\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# scatter plot instead of dense bars\n",
        "plt.scatter(out_deg, out_cnt, color='green', s=20, alpha=0.6, edgecolors='k')\n",
        "\n",
        "# use log–log scale (better for heavy-tailed data)\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.xlabel(\"Node out-degree\", fontsize=16)\n",
        "plt.ylabel(\"Frequency\", fontsize=16)\n",
        "plt.title(\"Entire graph — Node out-degree distribution\", fontsize=18)\n",
        "plt.grid(True, which=\"both\", ls=\"--\", lw=0.5, alpha=0.7)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq7lbWIIjRyO"
      },
      "outputs": [],
      "source": [
        "out_degree_upper_bound = 250\n",
        "restricted_out_degree_sequence = [out_degree_sequence[i] for i in range(len(out_degree_sequence)) if out_degree_sequence[i] <= out_degree_upper_bound]  # degree sequence for nx v2\n",
        "restricted_out_degree_count = collections.Counter(restricted_out_degree_sequence)\n",
        "restricted_out_deg, restricted_out_cnt = zip(*restricted_out_degree_count.items())\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.bar(restricted_out_deg, restricted_out_cnt, width=1, color='g')\n",
        "plt.xlabel(\"Node out-degree size\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Zoom - Node out-degree distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_LuvsE4jRyO"
      },
      "outputs": [],
      "source": [
        "# larger variance in out-degree - following activity (I follow a lot of people)\n",
        "# motivation: behavior that we want to check in the data (mention at the beginning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgk-Bg0NjRyO"
      },
      "source": [
        "# VII - Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCMCw4BMjRyP"
      },
      "outputs": [],
      "source": [
        "# switch that to the sanity check portion of the recitation\n",
        "print(nx.is_connected(G))\n",
        "print(nx.number_connected_components(G))\n",
        "print(nx.is_bipartite(G))\n",
        "print(list(nx.find_cycle(G, orientation='ignore')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN1JGOLVjRyP"
      },
      "outputs": [],
      "source": [
        "#Active learning: get the diameter, clustering coefficient (link to a page)\n",
        "# modularity, density, etc.\n",
        "# get familiarized with these metrics before we go to the centrlaty recitation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf-1DGh1jRyP"
      },
      "source": [
        "## 1) Network Layout\n",
        "\n",
        "People make their careers inventing layout algorithms! We'll choose a simple one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ot7NRCRjRyP"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "spring_pos = nx.spring_layout(G) # might take a little while\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to get the graph layout: ', elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iTqO45-jRyP"
      },
      "source": [
        "## 2) Basic plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liXom5Q6jRyP"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (20, 10))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "node_size_default = 40\n",
        "\n",
        "n = nx.draw_networkx(G,\n",
        "                     spring_pos,\n",
        "                     ax = ax,\n",
        "                     node_size = node_size_default,\n",
        "                     with_labels = False)\n",
        "plt.title(\"Entire graph - Default node size\")\n",
        "plt.close();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "megzlmgZjRyP"
      },
      "source": [
        "# How does it look?..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyT2H0X7jRyP"
      },
      "outputs": [],
      "source": [
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABZipO2cjRyP"
      },
      "source": [
        "## 3) Taking into account node sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9F3br7ujRyP"
      },
      "outputs": [],
      "source": [
        "deg = G.degree()         # compute the degree of each node, as a dict\n",
        "sizes = np.array([deg[i] for i in G.nodes()])\n",
        "\n",
        "fig_node_size = plt.figure(figsize = (20, 10))\n",
        "ax = fig_node_size.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "node_size_scaling_default = 0.5\n",
        "\n",
        "n_node_size = nx.draw_networkx(G,\n",
        "        spring_pos,\n",
        "        ax = ax,\n",
        "        node_size = node_size_scaling_default * sizes,\n",
        "        with_labels = False)\n",
        "plt.title(\"Entire graph - Node size based on degree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phaI5uDOjRyP"
      },
      "source": [
        "# Let's peek..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4VKHqDhjRyP"
      },
      "outputs": [],
      "source": [
        "fig_node_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZahiHyrjRyP"
      },
      "source": [
        "# VIII - Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_FIAERfjRyP"
      },
      "source": [
        "**What other global characteristics of the graph would be easy to compute using networkx Python package?**\n",
        "\n",
        "These concepts should normally be a review from the lecture!\n",
        "\n",
        "- **Diameter** of the network (i.e., what is the maximum distance between any two nodes?)\n",
        "\n",
        "*Note: it only makes sense to talk about the diameter of a network if every node is connected, otherwise it will be infinity.*\n",
        "\n",
        "- **Density** of the graph (i.e., how many edges do we observe in the network, as compared to the total number of possible connections?)\n",
        "\n",
        "*Note: if the network consists in $n$ nodes, then there are $n(n-1)$ possible pairs of nodes if the directionality matters, and $\\frac{1}{2}.n(n-1)$ if it does not.*\n",
        "\n",
        "- **Clustering coefficient** of the network (i.e., measure of the degree to which nodes in a graph tend to cluster together)\n",
        "\n",
        "**See exercise at the end of this notebook, for you to practice on your own!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB8AdpmTjRyP"
      },
      "outputs": [],
      "source": [
        "# Exercise\n",
        "# Other characteristics of the graph\n",
        "def graph_characteristics(graph):\n",
        "    t = time.time()\n",
        "    graph_diameter = nx.diameter(graph)\n",
        "    elapsed = time.time() - t\n",
        "    print('Time elapsed to get the diameter: ', elapsed)\n",
        "\n",
        "    t = time.time()\n",
        "    graph_density = nx.density(graph)\n",
        "    elapsed = time.time() - t\n",
        "    print('Time elapsed to get the density: ', elapsed)\n",
        "\n",
        "    t = time.time()\n",
        "    graph_triangles = len(nx.triangles(graph))\n",
        "    elapsed = time.time() - t\n",
        "    print('Time elapsed to get the number of triangles: ', elapsed)\n",
        "\n",
        "    t = time.time()\n",
        "    graph_transitivity = nx.transitivity(graph)\n",
        "    elapsed = time.time() - t\n",
        "    print('Time elapsed to get the transitivity: ', elapsed)\n",
        "\n",
        "    t = time.time()\n",
        "    graph_avg_clustering = nx.average_clustering(graph)\n",
        "    elapsed = time.time() - t\n",
        "    print('Time elapsed to get the average clustering coefficient: ', elapsed)\n",
        "\n",
        "    print(\"Here is a quick overview of the graph profile: density = \" + '{:.4f}'.format(graph_density) + \",\\nnumber of triangles = \" + '{:d}'.format(graph_triangles) + \", transitivity = \" + '{:.4f}'.format(graph_transitivity) + \", average clustering coefficient = \" + '{:.4f}'.format(graph_avg_clustering))\n",
        "\n",
        "    return()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAOhUxrcjRyP"
      },
      "outputs": [],
      "source": [
        "# Example with graph G\n",
        "graph_characteristics(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3nxP_xkjRyP"
      },
      "source": [
        "# Part 2: centrality measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qLTJj9MjRyP"
      },
      "outputs": [],
      "source": [
        "# compute degree centrality\n",
        "t = time.time()\n",
        "deg = nx.degree_centrality(G)\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to compute degree centrality: ', elapsed)\n",
        "print(type(deg))\n",
        "nx.set_node_attributes(G, deg, 'deg')\n",
        "deg_visual = np.array(list(deg.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00Np8bc1jRyP"
      },
      "outputs": [],
      "source": [
        "# compute closeness centrality\n",
        "t = time.time()\n",
        "closeness = nx.closeness_centrality(G)\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to compute closeness centrality: ', elapsed)\n",
        "print(type(closeness))\n",
        "nx.set_node_attributes(G, closeness, 'closeness')\n",
        "closeness_visual = np.array(list(closeness.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2Vf6oXxjRyP"
      },
      "outputs": [],
      "source": [
        "# compute eigenvector centrality\n",
        "t = time.time()\n",
        "eig = nx.eigenvector_centrality(G)\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to compute eigenvector centrality: ', elapsed)\n",
        "print(type(eig))\n",
        "nx.set_node_attributes(G, eig, 'eig')\n",
        "eig_visual = np.array(list(eig.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYsCpmOCjRyP"
      },
      "outputs": [],
      "source": [
        "adj = nx.adjacency_matrix(G)\n",
        "# Maybe not needed?\n",
        "adj_spectrum = nx.adjacency_spectrum(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1jF37xzjRyP"
      },
      "outputs": [],
      "source": [
        "inv_max = 1/max(np.real(adj_spectrum))\n",
        "print(\"The inverse of the maximum eigenvalue of A, the adjacency matrix of the graph, is: \", inv_max)\n",
        "alpha_candidate = 0.5*inv_max\n",
        "print(\"A good candidate value for alpha must be strictly less than the inverse of the maximum eigenvalue, e.g., \", alpha_candidate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm7FlOYxjRyQ"
      },
      "outputs": [],
      "source": [
        "# compute Katz centrality\n",
        "t = time.time()\n",
        "katz = nx.katz_centrality(G, alpha = alpha_candidate, beta = inv_max)\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to compute Katz centrality: ', elapsed)\n",
        "print(type(katz))\n",
        "nx.set_node_attributes(G, katz, 'katz')\n",
        "katz_visual = np.array(list(katz.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfxF30iXjRyQ"
      },
      "outputs": [],
      "source": [
        "# compute page rank centrality\n",
        "t = time.time()\n",
        "page_rank = nx.pagerank(G, alpha = 0.85)\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to compute page rank centrality: ', elapsed)\n",
        "print(type(page_rank))\n",
        "nx.set_node_attributes(G, page_rank, 'page_rank')\n",
        "page_rank_visual = np.array(list(page_rank.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW6vp_8MjRyQ"
      },
      "outputs": [],
      "source": [
        "# compute hub/authority scores\n",
        "t = time.time()\n",
        "hubs, authorities = nx.hits(G)\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to compute hub and authority scores: ', elapsed)\n",
        "print(type(hubs))\n",
        "print(type(authorities))\n",
        "nx.set_node_attributes(G, hubs, 'hub')\n",
        "nx.set_node_attributes(G, authorities, 'authority')\n",
        "hubs_visual = np.array(list(hubs.values()))\n",
        "authorities_visual = np.array(list(authorities.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u00Cz4EwjRyQ"
      },
      "outputs": [],
      "source": [
        "# compute harmonic centrality\n",
        "t = time.time()\n",
        "harmonic = nx.harmonic_centrality(G)\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to compute harmonic centrality: ', elapsed)\n",
        "print(type(harmonic))\n",
        "nx.set_node_attributes(G, harmonic, 'harmonic')\n",
        "harmonic_visual = np.array(list(harmonic.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GSW_lA3jRyQ"
      },
      "outputs": [],
      "source": [
        "# compute betweeness centrality\n",
        "t = time.time()\n",
        "betw = nx.betweenness_centrality(G)\n",
        "elapsed = time.time() - t\n",
        "print('Time elapsed to compute betweeness centrality: ', elapsed)\n",
        "print(type(betw))\n",
        "nx.set_node_attributes(G, betw, 'betw')\n",
        "betw_visual = np.array(list(betw.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZNsPvv8jRyQ"
      },
      "outputs": [],
      "source": [
        "# Range of these centrality values\n",
        "print('Degree centrality range: ', network_metric_statistics(list(deg_visual)))\n",
        "print('Closeness centrality range: ', network_metric_statistics(list(closeness_visual)))\n",
        "print('Eigenvector centrality range: ', network_metric_statistics(list(eig_visual)))\n",
        "print('Katz centrality range: ', network_metric_statistics(list(katz_visual)))\n",
        "print('Page rank centrality range: ', network_metric_statistics(list(page_rank_visual)))\n",
        "print('Hub score range: ', network_metric_statistics(list(hubs_visual)))\n",
        "print('Authority score range: ', network_metric_statistics(list(authorities_visual)))\n",
        "print('Harmonic centrality range: ', network_metric_statistics(list(harmonic_visual)))\n",
        "print('Betweenness centrality range: ', network_metric_statistics(list(betw_visual)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSz2LHDTjRyQ"
      },
      "outputs": [],
      "source": [
        "fig_eig = plt.figure(figsize = (10, 10))\n",
        "ax = fig_eig.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "n_eig = nx.draw_networkx(G,\n",
        "                     spring_pos,\n",
        "                     ax = ax,\n",
        "                     node_size = 500*np.log(eig_visual+1) + 10, # just for visualization\n",
        "                     with_labels = False)\n",
        "plt.close(); # just for display on the slides"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0MZj_y3jRyQ"
      },
      "source": [
        "# How does it look?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n8RdVfwjRyQ"
      },
      "outputs": [],
      "source": [
        "fig_eig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMua9uXhjRyQ"
      },
      "outputs": [],
      "source": [
        "fig_eig_color = plt.figure(figsize = (10, 10))\n",
        "ax = fig_eig_color.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "eig_list = list(eig.values())\n",
        "colors = [eig_list[i] for i in range(len(G.nodes))]\n",
        "n_eig_color = nx.draw(G, spring_pos,\n",
        "            node_color = colors,\n",
        "            node_size = node_size_default, ax = ax, with_labels = False)\n",
        "plt.close(); # just for display on the slides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkhcHdqMjRyQ"
      },
      "outputs": [],
      "source": [
        "fig_eig_color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd4NdVX0jRyQ"
      },
      "outputs": [],
      "source": [
        "# We would like to zoom on the part of the network with higher eigenvector centrality than the rest\n",
        "nodes = G.nodes\n",
        "\n",
        "def has_top_x_centrality(n,x,centrality_type,centrality_list):\n",
        "    centrality_list_sorted = sorted(centrality_list,reverse=True)\n",
        "    idx = int(np.floor(x*len(nodes)))\n",
        "    centrality_threshold = centrality_list_sorted[idx]\n",
        "    return(1*(nodes[n][centrality_type] > centrality_threshold))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqdfk2OVjRyQ"
      },
      "outputs": [],
      "source": [
        "has_top_x_centrality(100,0.1,'eig',eig_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pveBbuVvjRyQ"
      },
      "outputs": [],
      "source": [
        "nodes[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoDshnSrjRyQ"
      },
      "outputs": [],
      "source": [
        "nodes_eig = [n for n in G.nodes\n",
        "                  if (has_top_x_centrality(n,0.1,'eig',eig_list) == 1)]\n",
        "nodes_eig[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ_J7nGUjRyQ"
      },
      "outputs": [],
      "source": [
        "subgraph_eig = [(n, u) for (n, u) in G.edges()\n",
        "    if (has_top_x_centrality(n,0.1,'eig',eig_list) == 1 or has_top_x_centrality(u,0.1,'eig',eig_list) == 1) ]\n",
        "\n",
        "subgraph_eig[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m84AnOufjRyQ"
      },
      "outputs": [],
      "source": [
        "S_eig = nx.Graph(subgraph_eig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UKKh0l_jRyQ"
      },
      "outputs": [],
      "source": [
        "# Look at the composition of this subgraph, that only has the 10% of nodes in terms of eigenvector centrality\n",
        "print(f\"Graph name: {S_eig.name}\")\n",
        "print(f\"Type: {type(S_eig)}\")\n",
        "print(f\"Number of nodes: {S_eig.number_of_nodes()}\")\n",
        "print(f\"Number of edges: {S_eig.number_of_edges()}\")\n",
        "print(f\"Is directed: {S_eig.is_directed()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml07YM_6jRyQ"
      },
      "outputs": [],
      "source": [
        "# Subgraph characteristics\n",
        "graph_characteristics(S_eig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZobXwklljRyQ"
      },
      "outputs": [],
      "source": [
        "subgraph_eig_deg = G.degree()         # compute the degree of each node, as a dict\n",
        "subgraph_eig_sizes = np.array([subgraph_eig_deg[i] for i in S_eig.nodes])\n",
        "\n",
        "#network_metric_statistics(subgraph_eig_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVeVVdw-jRyQ"
      },
      "outputs": [],
      "source": [
        "subgraph_eig_spring_pos = nx.spring_layout(S_eig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJIOIjB4jRyQ"
      },
      "outputs": [],
      "source": [
        "fig_subgraph_eig = plt.figure(figsize = (10, 10))\n",
        "ax = fig_subgraph_eig.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "n = nx.draw_networkx(S_eig,\n",
        "        subgraph_eig_spring_pos,\n",
        "        ax = ax,\n",
        "        node_size = node_size_scaling_default*subgraph_eig_sizes,\n",
        "        with_labels = False)\n",
        "\n",
        "plt.close();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNZMWLTZjRyQ"
      },
      "outputs": [],
      "source": [
        "fig_subgraph_eig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk9uQvokjRyR"
      },
      "outputs": [],
      "source": [
        "# What if we choose another centrality metric?\n",
        "\n",
        "# Degree\n",
        "nodes_deg = [n for n in G.nodes\n",
        "            if (has_top_x_centrality(n,0.1,'deg',deg.values()) == 1)]\n",
        "subgraph_deg = [(n, u) for (n, u) in G.edges()\n",
        "                if (has_top_x_centrality(n,0.1,'deg',deg.values()) == 1 or has_top_x_centrality(u,0.1,'deg',deg.values()) == 1)]\n",
        "\n",
        "S_deg = nx.Graph(subgraph_deg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBWLIi4yjRyR"
      },
      "outputs": [],
      "source": [
        "# Closeness\n",
        "nodes_closeness = [n for n in G.nodes\n",
        "                  if (has_top_x_centrality(n,0.1,'closeness',closeness.values()) == 1)]\n",
        "subgraph_closeness = [(n, u) for (n, u) in G.edges()\n",
        "                     if (has_top_x_centrality(n,0.1,'closeness',closeness.values()) == 1 or has_top_x_centrality(u,0.1,'closeness',closeness.values()) == 1)]\n",
        "\n",
        "\n",
        "S_closeness = nx.Graph(subgraph_closeness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYEKIdzpjRyR"
      },
      "outputs": [],
      "source": [
        "# Katz\n",
        "nodes_katz = [n for n in G.nodes\n",
        "             if (has_top_x_centrality(n,0.1,'katz',katz.values()) == 1)]\n",
        "subgraph_katz = [(n, u) for (n, u) in G.edges()\n",
        "    if (has_top_x_centrality(n,0.1,'katz',katz.values()) == 1 or has_top_x_centrality(u,0.1,'katz',katz.values()) == 1)]\n",
        "\n",
        "S_katz = nx.Graph(subgraph_katz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoP-QomVjRyR"
      },
      "outputs": [],
      "source": [
        "# Betweeness\n",
        "nodes_betw = [n for n in G.nodes\n",
        "             if (has_top_x_centrality(n,0.1,'betw',betw.values()) == 1)]\n",
        "subgraph_betw = [(n, u) for (n, u) in G.edges()\n",
        "                if (has_top_x_centrality(n,0.1,'betw',betw.values()) == 1 or has_top_x_centrality(u,0.1,'betw',betw.values()) == 1)]\n",
        "\n",
        "S_betw = nx.Graph(subgraph_betw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKfQKuBYjRyR"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    f\"Graph '{S_eig.name}' \"\n",
        "    f\"({ 'directed' if S_eig.is_directed() else 'undirected' }) \"\n",
        "    f\"with {S_eig.number_of_nodes()} nodes \"\n",
        "    f\"and {S_eig.number_of_edges()} edges\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDXrBMr1jRyR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Subgraph characteristics\n",
        "print(graph_characteristics(S_deg))\n",
        "print(graph_characteristics(S_closeness))\n",
        "print(graph_characteristics(S_katz))\n",
        "# page_rank\n",
        "# hub\n",
        "# authority\n",
        "# harmonic\n",
        "print(graph_characteristics(S_betw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbzM3h_XjRyR"
      },
      "outputs": [],
      "source": [
        "# Nodes and edges in common with S_eig?\n",
        "\n",
        "# Degree vs. eig\n",
        "nodes_deg_set = set(nodes_deg); subgraph_deg_set = set(subgraph_deg);\n",
        "nodes_eig_set = set(nodes_eig); subgraph_eig_set = set(subgraph_eig);\n",
        "\n",
        "nodes_deg_eig = nodes_deg_set.intersection(nodes_eig_set)\n",
        "nodes_deg_not_eig = nodes_deg_set.difference(nodes_eig_set)\n",
        "nodes_eig_not_deg = nodes_eig_set.difference(nodes_deg_set)\n",
        "\n",
        "edges_deg_eig = subgraph_deg_set.intersection(subgraph_eig_set)\n",
        "edges_deg_not_eig = subgraph_deg_set.difference(subgraph_eig_set)\n",
        "edges_eig_not_deg = subgraph_eig_set.difference(subgraph_deg_set)\n",
        "\n",
        "# Closeness vs. eig\n",
        "nodes_closeness_set = set(nodes_closeness); subgraph_closeness_set = set(subgraph_closeness);\n",
        "\n",
        "nodes_closeness_eig = nodes_closeness_set.intersection(nodes_eig_set)\n",
        "nodes_closeness_not_eig = nodes_closeness_set.difference(nodes_eig_set)\n",
        "nodes_eig_not_closeness = nodes_eig_set.difference(nodes_closeness_set)\n",
        "\n",
        "edges_closeness_eig = subgraph_closeness_set.intersection(subgraph_eig_set)\n",
        "edges_closeness_not_eig = subgraph_closeness_set.difference(subgraph_eig_set)\n",
        "edges_eig_not_closeness = subgraph_eig_set.difference(subgraph_closeness_set)\n",
        "\n",
        "# Katz vs. eig\n",
        "nodes_katz_set = set(nodes_katz); subgraph_katz_set = set(subgraph_katz);\n",
        "\n",
        "nodes_katz_eig = nodes_katz_set.intersection(nodes_eig_set)\n",
        "nodes_katz_not_eig = nodes_katz_set.difference(nodes_eig_set)\n",
        "nodes_eig_not_katz = nodes_eig_set.difference(nodes_katz_set)\n",
        "\n",
        "edges_katz_eig = subgraph_katz_set.intersection(subgraph_eig_set)\n",
        "edges_katz_not_eig = subgraph_katz_set.difference(subgraph_eig_set)\n",
        "edges_eig_not_katz = subgraph_eig_set.difference(subgraph_katz_set)\n",
        "\n",
        "# Page rank vs. eig\n",
        "\n",
        "# Hub vs. eig\n",
        "\n",
        "# Authority vs. eig\n",
        "\n",
        "# Harmonic vs. eig\n",
        "\n",
        "# Betweeness vs. eig\n",
        "nodes_betw_set = set(nodes_betw); subgraph_betw_set = set(subgraph_betw);\n",
        "\n",
        "node_betw_eig = nodes_betw_set.intersection(nodes_eig_set)\n",
        "nodes_betw_not_eig = nodes_betw_set.difference(nodes_eig_set)\n",
        "nodes_eig_not_betw = nodes_eig_set.difference(nodes_betw_set)\n",
        "\n",
        "edges_betw_eig = subgraph_betw_set.intersection(subgraph_eig_set)\n",
        "edges_betw_not_eig = subgraph_betw_set.difference(subgraph_eig_set)\n",
        "edges_eig_not_betw = subgraph_eig_set.difference(subgraph_betw_set)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0UsG0ozjRyR"
      },
      "outputs": [],
      "source": [
        "print(network_metric_statistics(subgraph_deg_sizes.tolist()))\n",
        "print(network_metric_statistics(subgraph_closeness_sizes.tolist()))\n",
        "print(network_metric_statistics(subgraph_katz_sizes.tolist()))\n",
        "print(network_metric_statistics(subgraph_betw_sizes.tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADdP7NIFjRyR"
      },
      "outputs": [],
      "source": [
        "# Layouts\n",
        "subgraph_deg_spring_pos = nx.spring_layout(S_deg) # might take a little while\n",
        "subgraph_closeness_spring_pos = nx.spring_layout(S_closeness) # might take a little while\n",
        "subgraph_katz_spring_pos = nx.spring_layout(S_katz) # might take a little while\n",
        "subgraph_betw_spring_pos = nx.spring_layout(S_betw) # might take a little while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DImKvSVkjRyR"
      },
      "outputs": [],
      "source": [
        "# Figure based on degree\n",
        "fig_subgraph_deg = plt.figure(figsize = (10, 10))\n",
        "ax = fig_subgraph_deg.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "n = nx.draw_networkx(S_deg,\n",
        "        subgraph_deg_spring_pos,\n",
        "        ax = ax,\n",
        "        node_size = node_size_scaling_default*subgraph_deg_sizes,\n",
        "        with_labels = False)\n",
        "\n",
        "plt.close();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn_QMcFFjRyR"
      },
      "outputs": [],
      "source": [
        "fig_subgraph_deg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHAf38aujRyR"
      },
      "outputs": [],
      "source": [
        "# Figure based on closeness\n",
        "fig_subgraph_closeness = plt.figure(figsize = (10, 10))\n",
        "ax = fig_subgraph_closeness.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "n = nx.draw_networkx(S_closeness,\n",
        "        subgraph_closeness_spring_pos,\n",
        "        ax = ax,\n",
        "        node_size = node_size_scaling_default*subgraph_closeness_sizes,\n",
        "        with_labels = False)\n",
        "\n",
        "plt.close();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KqHiY5-jRyR"
      },
      "outputs": [],
      "source": [
        "fig_subgraph_closeness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIcakP8jjRyR"
      },
      "outputs": [],
      "source": [
        "# Figure based on Katz\n",
        "fig_subgraph_katz = plt.figure(figsize = (10, 10))\n",
        "ax = fig_subgraph_katz.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "n = nx.draw_networkx(S_katz,\n",
        "        subgraph_katz_spring_pos,\n",
        "        ax = ax,\n",
        "        node_size = node_size_scaling_default*subgraph_katz_sizes,\n",
        "        with_labels = False)\n",
        "\n",
        "plt.close();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzccGr0qjRyR"
      },
      "outputs": [],
      "source": [
        "fig_subgraph_katz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTrzQWrBjRyR"
      },
      "outputs": [],
      "source": [
        "# Figure based on betweeness\n",
        "fig_subgraph_betw = plt.figure(figsize = (10, 10))\n",
        "ax = fig_subgraph_betw.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "n = nx.draw_networkx(S_betw,\n",
        "        subgraph_betw_spring_pos,\n",
        "        ax = ax,\n",
        "        node_size = node_size_scaling_default*subgraph_betw_sizes,\n",
        "        with_labels = False)\n",
        "\n",
        "plt.close();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2iqZZswjRyR"
      },
      "outputs": [],
      "source": [
        "fig_subgraph_betw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxKETMq0jRyR"
      },
      "source": [
        "## Community Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvsl0HtvjRyR"
      },
      "source": [
        "It may be useful to *add attributes* to the nodes or edges of your graph. Nodes might have user data or flow sources or dynamical state variables. Edges might have weights or costs or capacities.   Networkx makes it easy to add this kind of information to the graph. As an example, let's make some community partitions, add them to the graph, and then visualize them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiqGX3VdjRyR"
      },
      "source": [
        "## Modularity Maximization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuoKnx9kjRyR"
      },
      "source": [
        "The classical **modularity** of a partition $c:\\mathcal{N} \\rightarrow [N]$ is defined to be\n",
        "\n",
        "$$\n",
        "Q \\triangleq \\frac{1}{2m} \\sum_{u,v \\in \\mathcal{N}} A_{uv} - \\frac{k_u k_v}{2m}\\delta(c(u), c(v))\\;.\n",
        "$$\n",
        "\n",
        "Intuitively, the modularity measures how many edges are observed *within* communities and compares that to a configuration null-model. High values of the modularity imply that there are many more edges within communities than would be expected. Many community-detection algorithms seek partitions that maximize $Q$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM8UclWsjRyR"
      },
      "source": [
        "## Modularity Maximization with Louvain\n",
        "\n",
        "The method below uses the [*Louvain algorithm*](https://en.wikipedia.org/wiki/Louvain_Modularity) to calculate community partitions with high modularity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_asd_GSOjRyR"
      },
      "outputs": [],
      "source": [
        "!pip install python_louvain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFqmbMeYjRyS"
      },
      "outputs": [],
      "source": [
        "from community import community_louvain # for nxv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MWYhcG1jRyS"
      },
      "outputs": [],
      "source": [
        "# partition = community.best_partition(G) # idk if this works for v1\n",
        "partition = community_louvain.best_partition(G)\n",
        "communities = [partition.get(node) for node in G.nodes()]\n",
        "print('The number of communities is ' + str(max(communities)) + '.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6XIkN6kjRyS"
      },
      "outputs": [],
      "source": [
        "# Let's assign each node to its given community\n",
        "nx.set_node_attributes(G, partition, name='community')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIDDubdgjRyS"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL0cdoQBjRyS"
      },
      "outputs": [],
      "source": [
        "colors = [G.nodes[n]['community'] for n in G.nodes]\n",
        "\n",
        "fig = plt.figure(figsize = (10, 10))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.axis('off')\n",
        "\n",
        "n = nx.draw_networkx(G,\n",
        "        spring_pos,\n",
        "        ax = ax,\n",
        "        node_size = node_size_default,\n",
        "        with_labels = False,\n",
        "        node_color = communities)\n",
        "\n",
        "plt.close();\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFI4lN-BjRyS"
      },
      "source": [
        "## How does it look?...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BtkBaoDjRyS"
      },
      "outputs": [],
      "source": [
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYm7rvDmjRyS"
      },
      "source": [
        "# Illustration of recitation on graphs/Laplacian/connected components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THZ0fuKCjRyS"
      },
      "outputs": [],
      "source": [
        "L = nx.laplacian_matrix(G)\n",
        "degree_matrix = np.diag(sizes)\n",
        "print(1*(L != (degree_matrix - adj)).sum())\n",
        "L_tilde = degree_matrix - adj\n",
        "\n",
        "print(L.shape)\n",
        "print(L_tilde.shape)\n",
        "print(type(L))\n",
        "print(type(L_tilde))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1qPzYJ4jRyS"
      },
      "outputs": [],
      "source": [
        "L_rank = np.linalg.matrix_rank(L_tilde)\n",
        "L_determinant = np.linalg.det(L_tilde)\n",
        "L_trace = np.trace(L_tilde)\n",
        "\n",
        "print('Rank of the Laplacian: ', L_rank)\n",
        "print('Determinant of the Laplacian: ', L_determinant)\n",
        "print('Trace of the Laplacian: ', L_trace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g4fQ_YhjRyS"
      },
      "outputs": [],
      "source": [
        "n = len(G.nodes)\n",
        "print('Number of nodes in the graph: ', n)\n",
        "print('Number of connected components: ', n-L_rank)\n",
        "print('Is the graph G acyclic?', L_rank == L_trace/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOCQVcHtjRyS"
      },
      "outputs": [],
      "source": [
        "# Find a cycle in the graph\n",
        "list(nx.find_cycle(G, orientation='ignore'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcsQwMqujRyS"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "G_cycles = nx.cycle_basis(G)\n",
        "elapsed = time.time() - t\n",
        "print('Time required to find all cycles: ', elapsed)\n",
        "\n",
        "# Let us confirm the hypothesis that a social network is predominantly made of cycles!\n",
        "print(len(G_cycles))\n",
        "G_cycle_ratio = len(G_cycles)/len(G.edges)*100\n",
        "print('Ratio of cycles in the graph: ', np.floor(G_cycle_ratio), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF6evACBjRyS"
      },
      "outputs": [],
      "source": [
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "c = list(greedy_modularity_communities(G))\n",
        "print(len(c))\n",
        "#sorted(c[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBtisc_jjRyS"
      },
      "source": [
        "# Learn More\n",
        "\n",
        "- NetworkX [examples](https://networkx.readthedocs.io/en/stable/examples/) and [tutorials](https://networkx.readthedocs.io/en/stable/tutorial/index.html).\n",
        "- Visualization demos on small (and classic!) karate club network: (https://aksakalli.github.io/2017/07/17/network-centrality-measures-and-their-visualization.html#degree-centrality)\n",
        "- A [nice reference](https://www.cl.cam.ac.uk/~cm542/teaching/2010/stna-pdfs/stna-lecture8.pdf) to some more advanced network analysis operations.\n",
        "- \"I need faster network algorithms!\" Check out [igraph](http://igraph.org/python/).\n",
        "- \"I work in `R`\": check out the [igraph](http://igraph.org/r/) and [tidygraph](https://www.data-imaginist.com/2017/introducing-tidygraph/) packages.\n",
        "- Mathematics of networks: There's this great course at MIT..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9ce52e0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}